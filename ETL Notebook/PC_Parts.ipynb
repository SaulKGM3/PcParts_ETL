{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec63d33-7c19-4a2f-b310-029dd25545fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47a07903-29ff-4099-a2fb-23ff5b8f5cbd",
   "metadata": {},
   "source": [
    "# ETL Process for PC PARTS Dataset\n",
    "\n",
    "This notebook performs a *semi automated ETL* process for sales, cost, and inventory data stored in the `PCPARTS_DB` database, with human validation. The database contains a mix of real and synthetic data. Once processed, the data is loaded into SQL Server and ready for use.\n",
    "\n",
    "## Performed Steps\n",
    "\n",
    "1. **Reading datasets** from local sources or previous transformations.\n",
    "2. **Connecting to SQL Server** using SQLAlchemy and ODBC.\n",
    "3. **Uploading dataframes** to the database:\n",
    "   - `df_ventas`\n",
    "   - `df_costos`\n",
    "   - `df_inventario`\n",
    "   - `inventario_agregado`\n",
    "   - `ventas_agregado`\n",
    "\n",
    "> *Connection credentials have been censored for security purposes.*\n",
    "\n",
    "> *This an ongoing project building and further refinement/improvement is pending to be implemented*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fb6245-b3dc-4724-a7a8-8d7bda9cbd18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12f76c57-71d4-4860-8698-849acff5f80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta de los archivos CSV\n",
    "ruta = r\"C://Users//PC USER//PC PART DB//Current month\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82766fcd-853d-441f-ba1b-9afd2e3a1ac1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inventory\n",
      "\n",
      "  Fecha_inventario       Sku  Stock_inicial  Stock_recibido  Stock_vendido  \\\n",
      "0       2023-04-01  Sku_0057             55              32             39   \n",
      "1       2023-04-08  Sku_0057             93              45            102   \n",
      "2       2023-04-15  Sku_0057             40              50             39   \n",
      "3       2023-04-22  Sku_0057             36              15             29   \n",
      "4       2023-04-01  Sku_0090             29               2              5   \n",
      "\n",
      "   Stock_final  Descontinuado Tienda_id  \n",
      "0           48          False  Tienda_1  \n",
      "1           36          False  Tienda_1  \n",
      "2           51          False  Tienda_1  \n",
      "3           22          False  Tienda_1  \n",
      "4           26          False  Tienda_1   \n",
      "\n",
      "Sales\n",
      "\n",
      "  Fecha_venta       Sku  Precio_unitario  Unidades_vendidas   Ingresos  \\\n",
      "0  2023-04-03  Sku_0053          9875.22                 26  256755.72   \n",
      "1  2023-04-03  Sku_0085          9204.58                  2   18409.16   \n",
      "2  2023-04-03  Sku_0048          4178.46                 11   45963.06   \n",
      "3  2023-04-03  Sku_0086          8580.67                 21  180194.07   \n",
      "4  2023-04-03  Sku_0095          8520.44                  9   76683.96   \n",
      "\n",
      "  Tienda_id  \n",
      "0  Tienda_1  \n",
      "1  Tienda_1  \n",
      "2  Tienda_1  \n",
      "3  Tienda_1  \n",
      "4  Tienda_1   \n",
      "\n",
      "Costs\n",
      "\n",
      "  Fecha_costo       Sku  Costo_unitario  Unidades_adquiridas  Gasto_total  \\\n",
      "0  2023-04-03  Sku_0000         8773.15                   32    280740.80   \n",
      "1  2023-04-03  Sku_0001         4933.40                   40    197336.00   \n",
      "2  2023-04-03  Sku_0002         7429.87                   43    319484.41   \n",
      "3  2023-04-03  Sku_0003         5499.34                   33    181478.22   \n",
      "4  2023-04-03  Sku_0004         7303.11                    0         0.00   \n",
      "\n",
      "  Tienda_id  \n",
      "0  Tienda_1  \n",
      "1  Tienda_1  \n",
      "2  Tienda_1  \n",
      "3  Tienda_1  \n",
      "4  Tienda_1   \n",
      "\n",
      "Aggregated Inventory\n",
      "\n",
      "  Fecha_inventario Tienda_id       Sku  Stock_inicial  Stock_final\n",
      "0       2023-04-30  Tienda_1  Sku_0000            232           88\n",
      "1       2023-04-30  Tienda_1  Sku_0008            200           86\n",
      "2       2023-04-30  Tienda_1  Sku_0022            213          172\n",
      "3       2023-04-30  Tienda_1  Sku_0025            183           65\n",
      "4       2023-04-30  Tienda_1  Sku_0027            529          404 \n",
      "\n",
      "Aggregated Sales\n",
      "\n",
      "  Fecha_venta Tienda_id       Sku  Unidades_vendidas   Ingresos\n",
      "0  2023-04-30  Tienda_1  Sku_0000                 19  112041.42\n",
      "1  2023-04-30  Tienda_1  Sku_0002                 13  117690.30\n",
      "2  2023-04-30  Tienda_1  Sku_0003                 50  255131.12\n",
      "3  2023-04-30  Tienda_1  Sku_0005                  8   71868.56\n",
      "4  2023-04-30  Tienda_1  Sku_0006                 40  266505.46 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "\n",
    "\n",
    "# Dictionary\n",
    "dataframes = {}\n",
    "\n",
    "# Function to normalize text\n",
    "def normalizar(texto):\n",
    "    return unicodedata.normalize('NFKD', str(texto)).encode('ASCII', 'ignore').decode('utf-8').lower().strip()\n",
    "\n",
    "# Loading and cleaning files name \n",
    "for archivo in os.listdir(ruta):\n",
    "    if archivo.endswith('.csv'):\n",
    "        nombre_df = archivo.replace('.csv', '').replace('-', '').replace(' ', '').replace('_', '')\n",
    "        nombre_df = normalizar(nombre_df).capitalize()\n",
    "\n",
    "        df = pd.read_csv(os.path.join(ruta, archivo))\n",
    "\n",
    "# Columns name cleaning\n",
    "        nuevas_columnas = []\n",
    "        for col in df.columns:\n",
    "            col = normalizar(col)\n",
    "            col = col.capitalize()\n",
    "            col = col.replace(' ', '_').replace('-', '_')\n",
    "\n",
    "            if col == \"Fecha\":\n",
    "                if \"inventario\" in nombre_df:\n",
    "                    col = f\"{col}_inventario\"\n",
    "                elif \"venta\" in nombre_df:\n",
    "                    col = f\"{col}_venta\"\n",
    "                elif \"costo\" in nombre_df:\n",
    "                    col = f\"{col}_costo\"\n",
    "                \n",
    "            nuevas_columnas.append(col)\n",
    "        df.columns = nuevas_columnas\n",
    "\n",
    "# Columns name cleaning\n",
    "\n",
    "        for col in df.select_dtypes(include='object').columns:\n",
    "            df[col] = df[col].apply(normalizar).str.capitalize()\n",
    "            if col.startswith(\"Fecha_\"):\n",
    "                df[col] = pd.to_datetime(df[col], errors='coerce')  \n",
    "\n",
    "        dataframes[nombre_df] = df  \n",
    "        \n",
    "# Groups by table type\n",
    "ventas = []\n",
    "inventario = []\n",
    "costos = []\n",
    "\n",
    "for nombre, df in dataframes.items():\n",
    "    if \"inventario\" in nombre:\n",
    "        inventario.append(df)\n",
    "    elif \"venta\" in nombre:\n",
    "        ventas.append(df)\n",
    "    elif \"costo\" in nombre:\n",
    "        costos.append(df)\n",
    "\n",
    "# Append tables\n",
    "df_ventas = pd.concat(ventas, ignore_index=True)\n",
    "df_inventario = pd.concat(inventario, ignore_index=True)\n",
    "df_costos = pd.concat(costos, ignore_index=True)\n",
    "\n",
    "TablasT = [ventas, inventario, costos]\n",
    "\n",
    "for z in TablasT:\n",
    "    for w in z:\n",
    "        if w.isnull().sum().sum()>0:\n",
    "            print(f\"NULLS IN {w.isnull().sum().sum()}\")\n",
    "\n",
    "\n",
    "# Aggregated Inventory\n",
    "\n",
    "inventario_agregado = df_inventario.groupby([\n",
    "    pd.Grouper(key='Fecha_inventario', freq='ME'),\n",
    "    'Tienda_id', 'Sku'\n",
    "]).agg({\n",
    "    'Stock_inicial': 'sum',    \n",
    "    'Stock_final': 'sum'       \n",
    "}).reset_index()\n",
    "\n",
    "# Aggregated Sales\n",
    "\n",
    "ventas_agregado = df_ventas.groupby([\n",
    "    pd.Grouper(key='Fecha_venta', freq='ME'), \n",
    "    'Tienda_id', 'Sku'\n",
    "]).agg({\n",
    "    'Unidades_vendidas': 'sum',\n",
    "    'Ingresos': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# For human validation before upload\n",
    "\n",
    "print(\"Inventory\\n\")\n",
    "print(df_inventario.head(), \"\\n\")\n",
    "\n",
    "print(\"Sales\\n\")\n",
    "print(df_ventas.head(), \"\\n\")\n",
    "\n",
    "print(\"Costs\\n\")\n",
    "print(df_costos.head(), \"\\n\")\n",
    "\n",
    "print(\"Aggregated Inventory\\n\")\n",
    "print(inventario_agregado.head(), \"\\n\")\n",
    "\n",
    "print(\"Aggregated Sales\\n\")\n",
    "print(ventas_agregado.head(), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3c70c0-2558-4425-a06d-8f171e61f05d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f9fbca-683a-4408-89f9-d11a25587456",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "51f99e52-c038-4c66-895c-14436c8f8dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload to SQL\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from urllib.parse import quote_plus\n",
    "\n",
    "cadena_odbc = (\n",
    "    \"*********\"\n",
    ")\n",
    "\n",
    "cadena_conexion = \"*********\" + quote_plus(cadena_odbc)\n",
    "engine = create_engine(cadena_conexion)\n",
    "\n",
    "df_ventas.to_sql('df_ventas', engine, if_exists='append', index=False)\n",
    "df_costos.to_sql('df_costos', engine, if_exists='append', index=False)\n",
    "df_inventario.to_sql('df_inventario', engine, if_exists='append', index=False)\n",
    "inventario_agregado.to_sql('inventario_agregado', engine, if_exists='append', index=False)\n",
    "ventas_agregado.to_sql('ventas_agregado', engine, if_exists='append', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435e56d8-8003-4881-b991-41bcbb68f8ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
