# PcParts_ETL
This project demonstrates a practical ETL process using synthetic data, showing each step from CSV data preparation and cleaning to transformation, consolidation, and loading into SQL, with a final Power BI dashboard for illustration.

**Note**: The main goal is to illustrate a complete ETL workflow, not to generate business insights from real data. If you are looking for a project focused on real world data exploration and performance, please refer to my [Brazilian Ecommerce Review Analysis](https://github.com/SaulKGM3/Brazilian_Ecommerce_Review_Analysis), which leverages machine learning models to extract insights from real datasets.
.

## Project structure
- **ETL Notebook**
Contains the full code for data cleaning, transformation, and loading. Personal info is anonymized.

- **Dashboard**
Includes images of the Power BI dashboard illustrating the output stage of the ETL process.

## ETL Workflow Summary

Below you can find a visual summary of the ETL process steps included in this project:

1. **Raw files in CSV format**  
   ![Raw Files on CSV](Flow%20Images/Raw%20Files%20on%20CSV.png)

2. **Data cleaning and transformation in the notebook**  
   ![Notebook Code](Flow%20Images/Notebook%20Code.png)

3. **Data upload from Python to SQL**  
   ![Python To SQL](Flow%20Images/Python%20To%20SQL.png)

4. **Validation of loaded data in SQL**  
   ![SQL Data Validation](Flow%20Images/SQL%20Data%20Validation.png)

5. **Data loaded into Power BI from SQL**  
   ![Data Load Into Power BI From SQL](Flow%20Images/Data%20Load%20Into%20Power%20BI%20From%20SQL.png)

6. **Power BI dashboard**  
   ![ETL Dashboard](Flow%20Images/ETL%20Dashboard.png)


## Notes and pending improvements

- This is a work in progress.

- The notebook currently contains comments in Spanish, this will be switched to English soon for clarity.

- Synthetic data will be further optimized for more realistic behavior and distribution.

- The code is fully functional but will be refactored for better structure and readability.
